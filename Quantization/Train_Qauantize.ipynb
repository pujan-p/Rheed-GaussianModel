{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables: \n",
    "\n",
    "YES = 1\n",
    "NO = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Training\n",
    "check_GPU = NO\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import least_squares\n",
    "from dask import delayed, compute\n",
    "from dask.distributed import Client\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "output_scaler = StandardScaler()\n",
    "if(check_GPU):\n",
    "    print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normalized Images Shape]: (150985, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "# Read H5 Data File:\n",
    "data_dir = '/mnt/Research/Data/' # Change to your DATA PATH\n",
    "\n",
    "RHEED_data_file = data_dir + 'RHEED_4848_test6.h5'\n",
    "spot = 'spot_2'\n",
    "h5 = h5py.File(RHEED_data_file, 'r')\n",
    "\n",
    "raw_data = []\n",
    "for growth in h5.keys():\n",
    "    raw_data.extend(h5[growth][spot])\n",
    "raw_data = np.array(raw_data).astype(np.float32)\n",
    "\n",
    "normalized_images = []\n",
    "for image in raw_data:\n",
    "    normalized_images.append(image / np.max(image))\n",
    "normalized_images = np.array(normalized_images).astype(np.float32)\n",
    "\n",
    "print(f'[Normalized Images Shape]: {normalized_images.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate Data Array:\n",
    "validate_data_array = NO\n",
    "\n",
    "if validate_data_array:\n",
    "    rand_int = np.random.randint(low=0, high=normalized_images.shape[0])\n",
    "    print(f'[Normalized Image #{rand_int}]:')\n",
    "    plt.imshow(normalized_images[rand_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for estimating labels\n",
    "\n",
    "# generate 2d Gaussian from its parameters\n",
    "# x, y = x-coord, y-coord\n",
    "# A = amplitude\n",
    "# x0, y0 = mean-x, mean-y\n",
    "# sigma_x, sigma_y = std.-dev.-x, std.-dev.-y\n",
    "def gaussian_2D(x, y, A, x0, y0, sigma_x, sigma_y):\n",
    "    return A * np.exp(-((x - x0)**2 / (2 * sigma_x**2) + (y - y0)**2 / (2 * sigma_y**2)))\n",
    "\n",
    "# Initial guess for each parameter\n",
    "# data = normalized image\n",
    "def add_guess(data):\n",
    "    A_guess = np.max(data)\n",
    "    x0_guess, y0_guess = np.unravel_index(np.argmax(data), data.shape)\n",
    "    sigma_x_guess = sigma_y_guess = np.std(data)\n",
    "    return [A_guess, x0_guess, y0_guess, sigma_x_guess, sigma_y_guess]\n",
    "\n",
    "# Compute residuals\n",
    "# params = A, x0, y0, sigma_x, sigma_y\n",
    "# x, y  = x-coord, y-coord\n",
    "# data = normalized image\n",
    "def residuals(params, x, y, data):\n",
    "    A, x0, y0, sigma_x, sigma_y = params\n",
    "    model = gaussian_2D(x, y, A, x0, y0, sigma_x, sigma_y)\n",
    "    return (model - data).ravel()\n",
    "\n",
    "# Convert parameters from A, x0, y0, sigma_x, sigma_y --> mean_x, mean_y, cov_x, cov_y, theta\n",
    "# params = A, x0, y0, sigma_x, sigma_y\n",
    "def convert_parameters(parameters):\n",
    "    A, x0, y0, sigma_x, sigma_y = parameters\n",
    "    mean_x = x0\n",
    "    mean_y = y0\n",
    "    cov_x = sigma_x\n",
    "    cov_y = sigma_y\n",
    "\n",
    "    if cov_x != 0 and cov_y != 0:\n",
    "        theta = 0.5 * np.arctan(2 * cov_x * cov_y / (cov_x**2 - cov_y**2)+1e-9)\n",
    "    else:\n",
    "        theta = 0.0\n",
    "\n",
    "    return mean_x, mean_y, cov_x, cov_y, theta\n",
    "\n",
    "@delayed\n",
    "def fit_gaussian_2D_delayed(data, guess):\n",
    "    y, x = np.indices(data.shape)\n",
    "    result = least_squares(residuals, guess, args=(x, y, data))\n",
    "    return result.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Estimated Labels Shape]: (150985, 5)\n"
     ]
    }
   ],
   "source": [
    "# Estimate Labels:\n",
    "load_labels = YES # (Takes <1 min to load, ~40 mins to generate)\n",
    "\n",
    "# Import From File\n",
    "\n",
    "if load_labels:\n",
    "    RHEED_label_file = data_dir + 'Labels.npy'\n",
    "    estimated_labels = np.load(RHEED_label_file)\n",
    "    # estimated_labels = np.random.rand(normalized_images.shape[0], 5)\n",
    "\n",
    "# Generate\n",
    "else:\n",
    "    estimated_labels = []\n",
    "    with Client() as client:\n",
    "        guesses = [add_guess(image) for image in normalized_images]\n",
    "        fits = [fit_gaussian_2D_delayed(image, guess) for image, guess in zip(normalized_images, guesses)]\n",
    "        estimated_labels = [convert_parameters(params) for params in compute(*fits)]\n",
    "    estimated_labels = np.array(estimated_labels).astype(np.float32)\n",
    "\n",
    "print(f'[Estimated Labels Shape]: {estimated_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 18:07:51.410835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-15 18:07:51.413531: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-01-15 18:07:51.413569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2025-01-15 18:07:51.413599: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2025-01-15 18:07:51.413628: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2025-01-15 18:07:51.413658: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2025-01-15 18:07:51.413688: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2025-01-15 18:07:51.413716: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2025-01-15 18:07:51.413745: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2025-01-15 18:07:51.413751: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-01-15 18:07:51.414671: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataSet:\n",
    "batch_size = 1000\n",
    "\n",
    "with tf.device('CPU'):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(normalized_images)\n",
    "    dataset = dataset.shuffle(normalized_images.shape[0], reshuffle_each_iteration=True)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "output_scaler.fit(estimated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Function: (TENSORFLOW)\n",
    "print_example_guassian = NO\n",
    "\n",
    "# mean_x, mean_y, cov_x, cov_y, theta\n",
    "def generate_guassian(batch, image_shape):\n",
    "    batch_size = batch.shape[0]\n",
    "    mean_x, mean_y, cov_x, cov_y, theta = tf.unstack(batch, axis=-1)\n",
    "    x = tf.range(image_shape[1], dtype=tf.float32)[:, tf.newaxis]\n",
    "    x = tf.tile(x, [1, image_shape[0]])\n",
    "\n",
    "    y = tf.range(image_shape[0], dtype=tf.float32)[tf.newaxis, :]\n",
    "    y = tf.tile(y, [image_shape[1], 1])\n",
    "\n",
    "    x = tf.tile(tf.expand_dims(x, 0), [batch_size, 1, 1])\n",
    "    y = tf.tile(tf.expand_dims(y, 0), [batch_size, 1, 1])\n",
    "\n",
    "    rota_matrix = tf.stack([tf.cos(theta), -tf.sin(theta), tf.sin(theta), tf.cos(theta)], axis=-1)\n",
    "    rota_matrix = tf.reshape(rota_matrix, (batch_size, 2, 2))\n",
    "\n",
    "    xy = tf.stack([x - tf.reshape(mean_x, (-1, 1, 1)), y - tf.reshape(mean_y, (-1, 1, 1))], axis=-1)\n",
    "    xy = tf.einsum('bijk,bkl->bijl', xy, rota_matrix)\n",
    "\n",
    "    img = tf.exp(-0.5 * (xy[:, :, :, 0]**2 / tf.reshape(cov_x, (-1, 1, 1))**2 + xy[:, :, :, 1]**2 / tf.reshape(cov_y, (-1, 1, 1))**2))\n",
    "\n",
    "    return tf.expand_dims(img, axis=-1) # if (batch_size, height, width, channels)\n",
    "    # return tf.expand_dims(img, axis=1) # 1 if (batch_size, channels, height, width)\n",
    "\n",
    "if print_example_guassian:\n",
    "    image_shape = (48, 48)\n",
    "    batch = tf.convert_to_tensor([\n",
    "        [21.8558168, 24.50041009, 10.31268177, 9.1700225, 0.72681534]\n",
    "        , [21.76068143, 24.37956637, 10.30043488, 9.15426013, 0.72655111]\n",
    "        , [21.72363929, 24.31050759, 10.33800891, 9.18570812, 0.72644599]\n",
    "        , [21.72777699, 24.29306623, 10.30178808, 9.14728058, 0.72610718]\n",
    "        , [21.79849472, 24.34649405, 10.32683150, 9.16259293, 0.72573213]\n",
    "    ])\n",
    "    generated_imgs = generate_guassian(batch, image_shape)\n",
    "    plt.imshow(tf.squeeze(generated_imgs[0]))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Loss Function (TENSORFLOW):\n",
    "print_example_loss = NO\n",
    "\n",
    "def custom_weighted_mse_loss(I, J, n):\n",
    "  W = tf.pow(I, n)\n",
    "\n",
    "  squared_diffs = tf.pow(I - J, 2)\n",
    "\n",
    "  weighted_squared_diffs = W * squared_diffs\n",
    "\n",
    "  loss = tf.reduce_mean(weighted_squared_diffs)\n",
    "\n",
    "  return loss\n",
    "\n",
    "if print_example_loss:\n",
    "  I = tf.random.normal((5, 1, 48, 48))\n",
    "  J = tf.random.normal((5, 1, 48, 48))\n",
    "  n = 2\n",
    "  loss = custom_weighted_mse_loss(I, J, n)\n",
    "  print(\"[Custom Weighted MSE Loss]:\", loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(filters=6, kernel_size=5, strides=1, padding='valid'),\n",
    "        tf.keras.layers.BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-05),  # if (batch_size, height, width, channels)\n",
    "        # tf.keras.layers.BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05), # if (batch_size, channels, height, width)\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=4, strides=4),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=1, padding='valid'),\n",
    "        tf.keras.layers.BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-05), # if (batch_size, height, width, channels)\n",
    "        # tf.keras.layers.BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05), # if (batch_size, channels, height, width)\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units=98, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=52, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss=custom_weighted_mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "train_model = NO\n",
    "save_model = NO\n",
    "load_model = YES\n",
    "model_summary = NO\n",
    "Gaussian_Model_dir = data_dir + 'Models/'\n",
    "Gaussian_Model_file = Gaussian_Model_dir + 'Gaussian_Model.keras'\n",
    "\n",
    "if train_model:\n",
    "    best_loss = float('inf')\n",
    "    num_epochs = 200\n",
    "    lr = 0.0001\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    n = 1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            n += 0.1\n",
    "\n",
    "        for image_batch in tqdm(dataset): \n",
    "            image_batch = tf.expand_dims(image_batch, axis=-1) # if (batch_size, height, width, channels)\n",
    "            # image_batch = tf.expand_dims(image_batch, axis=1) # if (batch_size, channels, height, width)\n",
    "            with tf.GradientTape() as tape:\n",
    "                embedding = model(image_batch)\n",
    "                unscaled_param = tf.constant(embedding * output_scaler.var_ ** 0.5 + output_scaler.mean_)\n",
    "                final = generate_guassian(unscaled_param, (48,48))\n",
    "                loss = custom_weighted_mse_loss(image_batch, final, n)\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            running_loss += loss.numpy()\n",
    "        average_loss = running_loss / len(dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss}\")\n",
    "\n",
    "if (save_model and not load_model):\n",
    "    model.save(Gaussian_Model_file)\n",
    "\n",
    "if (load_model and not save_model):\n",
    "    with tf.keras.utils.custom_object_scope({'custom_weighted_mse_loss': custom_weighted_mse_loss}):\n",
    "        model = tf.keras.models.load_model(Gaussian_Model_file)\n",
    "\n",
    "if model_summary:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Quantizing\n",
    "\n",
    "import qkeras\n",
    "from qkeras.estimate import print_qstats\n",
    "from qkeras.utils import model_quantize\n",
    "from qkeras.utils import quantized_model_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Post Training Quantization\n",
    "save_qmodel = YES\n",
    "view_qstats = NO\n",
    "fractional = 4\n",
    "integer = 0\n",
    "total_bits = fractional + integer\n",
    "Quantized_Gaussian_Model_file = Gaussian_Model_dir + f'Gaussian_Model_{total_bits}_{integer}.keras'\n",
    "\n",
    "q_dict = {\n",
    "    \"QConv2D\": {\n",
    "        \"kernel_quantizer\": f\"quantized_bits({total_bits},{integer},1)\",\n",
    "        \"bias_quantizer\": f\"quantized_bits({total_bits},{integer},1)\"\n",
    "    },\n",
    "    \"QDense\": {\n",
    "        \"kernel_quantizer\": f\"quantized_bits({total_bits},{integer},1)\",\n",
    "        \"bias_quantizer\": f\"quantized_bits({total_bits},{integer},1)\"\n",
    "    },\n",
    "    \"QBatchNormalization\": {},\n",
    "\n",
    "    \"QActivation\": f\"quantized_relu({total_bits},{integer})\"\n",
    "}\n",
    "\n",
    "qmodel = model_quantize(model, q_dict, total_bits, transfer_weights=True)\n",
    "\n",
    "\n",
    "if save_qmodel:\n",
    "    qmodel.save(Quantized_Gaussian_Model_file)\n",
    "\n",
    "if view_qstats:\n",
    "    print_qstats(qmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Synthesizing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls4ml-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
