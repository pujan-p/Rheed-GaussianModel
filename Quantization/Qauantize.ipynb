{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables: \n",
    "\n",
    "YES = 1\n",
    "NO = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive:\n",
    "using_google_drive = NO\n",
    "\n",
    "if using_google_drive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 04:47:24.377802: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-31 04:47:24.434229: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-12-31 04:47:24.434245: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-12-31 04:47:24.865025: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-12-31 04:47:24.865087: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-12-31 04:47:24.865105: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 04:47:25.442842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-31 04:47:25.445663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-12-31 04:47:25.445701: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-31 04:47:25.445731: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-31 04:47:25.445759: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-31 04:47:25.445788: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-31 04:47:25.445817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-31 04:47:25.445845: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-31 04:47:25.445873: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-12-31 04:47:25.445879: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Imports for Training\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import least_squares\n",
    "from dask import delayed, compute\n",
    "from dask.distributed import Client\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "output_scaler = StandardScaler()\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normalized Images Shape]: (150985, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "# Read H5 Data File:\n",
    "DATA_DIR = '/mnt/Research/Data/' # Change to your DATA PATH\n",
    "\n",
    "RHEED_DATA_FILE = DATA_DIR + 'RHEED_4848_test6.h5'\n",
    "spot = 'spot_2'\n",
    "h5 = h5py.File(RHEED_DATA_FILE, 'r')\n",
    "\n",
    "raw_data = []\n",
    "for growth in h5.keys():\n",
    "    raw_data.extend(h5[growth][spot])\n",
    "raw_data = np.array(raw_data).astype(np.float32)\n",
    "\n",
    "normalized_images = []\n",
    "for image in raw_data:\n",
    "    normalized_images.append(image / np.max(image))\n",
    "normalized_images = np.array(normalized_images).astype(np.float32)\n",
    "\n",
    "print(f'[Normalized Images Shape]: {normalized_images.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Normalized Image #131670]:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validate Data Array:\n",
    "validate_data_array = YES\n",
    "\n",
    "if validate_data_array:\n",
    "    rand_int = np.random.randint(low=0, high=normalized_images.shape[0])\n",
    "    print(f'[Normalized Image #{rand_int}]:')\n",
    "    plt.imshow(normalized_images[rand_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for estimating labels\n",
    "\n",
    "# generate 2d Gaussian from its parameters\n",
    "# x, y = x-coord, y-coord\n",
    "# A = amplitude\n",
    "# x0, y0 = mean-x, mean-y\n",
    "# sigma_x, sigma_y = std.-dev.-x, std.-dev.-y\n",
    "def gaussian_2D(x, y, A, x0, y0, sigma_x, sigma_y):\n",
    "    return A * np.exp(-((x - x0)**2 / (2 * sigma_x**2) + (y - y0)**2 / (2 * sigma_y**2)))\n",
    "\n",
    "# Initial guess for each parameter\n",
    "# data = normalized image\n",
    "def add_guess(data):\n",
    "    A_guess = np.max(data)\n",
    "    x0_guess, y0_guess = np.unravel_index(np.argmax(data), data.shape)\n",
    "    sigma_x_guess = sigma_y_guess = np.std(data)\n",
    "    return [A_guess, x0_guess, y0_guess, sigma_x_guess, sigma_y_guess]\n",
    "\n",
    "# Compute residuals\n",
    "# params = A, x0, y0, sigma_x, sigma_y\n",
    "# x, y  = x-coord, y-coord\n",
    "# data = normalized image\n",
    "def residuals(params, x, y, data):\n",
    "    A, x0, y0, sigma_x, sigma_y = params\n",
    "    model = gaussian_2D(x, y, A, x0, y0, sigma_x, sigma_y)\n",
    "    return (model - data).ravel()\n",
    "\n",
    "# Convert parameters from A, x0, y0, sigma_x, sigma_y --> mean_x, mean_y, cov_x, cov_y, theta\n",
    "# params = A, x0, y0, sigma_x, sigma_y\n",
    "def convert_parameters(parameters):\n",
    "    A, x0, y0, sigma_x, sigma_y = parameters\n",
    "    mean_x = x0\n",
    "    mean_y = y0\n",
    "    cov_x = sigma_x\n",
    "    cov_y = sigma_y\n",
    "\n",
    "    if cov_x != 0 and cov_y != 0:\n",
    "        theta = 0.5 * np.arctan(2 * cov_x * cov_y / (cov_x**2 - cov_y**2)+1e-9)\n",
    "    else:\n",
    "        theta = 0.0\n",
    "\n",
    "    return mean_x, mean_y, cov_x, cov_y, theta\n",
    "\n",
    "@delayed\n",
    "def fit_gaussian_2D_delayed(data, guess):\n",
    "    y, x = np.indices(data.shape)\n",
    "    result = least_squares(residuals, guess, args=(x, y, data))\n",
    "    return result.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Estimated Labels Shape]: (150985, 5)\n"
     ]
    }
   ],
   "source": [
    "# Estimate Labels:\n",
    "load_labels = YES # (Takes <1 min to load, ~40 mins to generate)\n",
    "\n",
    "# Import From File\n",
    "\n",
    "if load_labels:\n",
    "    RHEED_LABEL_FILE = DATA_DIR + 'Labels.npy'\n",
    "    estimated_labels = np.load(RHEED_LABEL_FILE)\n",
    "    # estimated_labels = np.random.rand(normalized_images.shape[0], 5)\n",
    "\n",
    "# Generate\n",
    "else:\n",
    "    estimated_labels = []\n",
    "    with Client() as client:\n",
    "        guesses = [add_guess(image) for image in normalized_images]\n",
    "        fits = [fit_gaussian_2D_delayed(image, guess) for image, guess in zip(normalized_images, guesses)]\n",
    "        estimated_labels = [convert_parameters(params) for params in compute(*fits)]\n",
    "    estimated_labels = np.array(estimated_labels).astype(np.float32)\n",
    "\n",
    "print(f'[Estimated Labels Shape]: {estimated_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 04:48:04.593257: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-31 04:48:04.595840: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1391477760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataSet:\n",
    "batch_size = 1000\n",
    "\n",
    "with tf.device('CPU'):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(normalized_images)\n",
    "    dataset = dataset.shuffle(normalized_images.shape[0], reshuffle_each_iteration=True)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "output_scaler.fit(estimated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Function: (TENSORFLOW)\n",
    "print_example_guassian = NO\n",
    "\n",
    "# mean_x, mean_y, cov_x, cov_y, theta\n",
    "def generate_guassian(batch, image_shape):\n",
    "    batch_size = batch.shape[0]\n",
    "    mean_x, mean_y, cov_x, cov_y, theta = tf.unstack(batch, axis=-1)\n",
    "    x = tf.range(image_shape[1], dtype=tf.float32)[:, tf.newaxis]\n",
    "    x = tf.tile(x, [1, image_shape[0]])\n",
    "\n",
    "    y = tf.range(image_shape[0], dtype=tf.float32)[tf.newaxis, :]\n",
    "    y = tf.tile(y, [image_shape[1], 1])\n",
    "\n",
    "    x = tf.tile(tf.expand_dims(x, 0), [batch_size, 1, 1])\n",
    "    y = tf.tile(tf.expand_dims(y, 0), [batch_size, 1, 1])\n",
    "\n",
    "    rota_matrix = tf.stack([tf.cos(theta), -tf.sin(theta), tf.sin(theta), tf.cos(theta)], axis=-1)\n",
    "    rota_matrix = tf.reshape(rota_matrix, (batch_size, 2, 2))\n",
    "\n",
    "    xy = tf.stack([x - tf.reshape(mean_x, (-1, 1, 1)), y - tf.reshape(mean_y, (-1, 1, 1))], axis=-1)\n",
    "    xy = tf.einsum('bijk,bkl->bijl', xy, rota_matrix)\n",
    "\n",
    "    img = tf.exp(-0.5 * (xy[:, :, :, 0]**2 / tf.reshape(cov_x, (-1, 1, 1))**2 + xy[:, :, :, 1]**2 / tf.reshape(cov_y, (-1, 1, 1))**2))\n",
    "\n",
    "    return tf.expand_dims(img, axis=1)\n",
    "\n",
    "if print_example_guassian:\n",
    "    image_shape = (48, 48)\n",
    "    batch = tf.convert_to_tensor([\n",
    "        [21.8558168, 24.50041009, 10.31268177, 9.1700225, 0.72681534]\n",
    "        , [21.76068143, 24.37956637, 10.30043488, 9.15426013, 0.72655111]\n",
    "        , [21.72363929, 24.31050759, 10.33800891, 9.18570812, 0.72644599]\n",
    "        , [21.72777699, 24.29306623, 10.30178808, 9.14728058, 0.72610718]\n",
    "        , [21.79849472, 24.34649405, 10.32683150, 9.16259293, 0.72573213]\n",
    "    ])\n",
    "    generated_imgs = generate_guassian(batch, image_shape)\n",
    "    plt.imshow(tf.squeeze(generated_imgs[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Custom Weighted MSE Loss]: 3.9485857\n"
     ]
    }
   ],
   "source": [
    "# Custom Loss Function (TENSORFLOW):\n",
    "print_example_loss = YES\n",
    "\n",
    "def custom_weighted_mse_loss(I, J, n):\n",
    "  W = tf.pow(I, n)\n",
    "\n",
    "  squared_diffs = tf.pow(I - J, 2)\n",
    "\n",
    "  weighted_squared_diffs = W * squared_diffs\n",
    "\n",
    "  loss = tf.reduce_mean(weighted_squared_diffs)\n",
    "\n",
    "  return loss\n",
    "\n",
    "if print_example_loss:\n",
    "  I = tf.random.normal((5, 1, 48, 48))\n",
    "  J = tf.random.normal((5, 1, 48, 48))\n",
    "  n = 2\n",
    "  loss = custom_weighted_mse_loss(I, J, n)\n",
    "  print(\"[Custom Weighted MSE Loss]:\", loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [   \n",
    "        tf.keras.layers.Conv2D(filters=6, kernel_size=5, strides=1, padding='valid', input_shape=(48, 48, 1)) # (batch_size, height, width, channels)\n",
    "        , tf.keras.layers.BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05)\n",
    "        , tf.keras.layers.ReLU()\n",
    "        , tf.keras.layers.MaxPool2D(pool_size=4, strides=4)\n",
    "\n",
    "        , tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=1, padding='valid')\n",
    "        , tf.keras.layers.BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05)\n",
    "        , tf.keras.layers.ReLU()\n",
    "        , tf.keras.layers.MaxPool2D(pool_size=2, strides=2)\n",
    "\n",
    "        , tf.keras.layers.Flatten()\n",
    "        , tf.keras.layers.Dense(units=98, activation='relu')\n",
    "        , tf.keras.layers.Dense(units=52, activation='relu')\n",
    "        , tf.keras.layers.Dense(units=5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss=custom_weighted_mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "train_model = YES\n",
    "save_model = NO\n",
    "load_model = NO\n",
    "\n",
    "if train_model:\n",
    "    best_loss = float('inf')\n",
    "    num_epochs = 200\n",
    "    lr = 0.0001\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    n = 1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            n += 0.1\n",
    "\n",
    "        for image_batch in tqdm(dataset): \n",
    "            image_batch = tf.expand_dims(image_batch, axis=3) # (batch_size, height, width, channels)\n",
    "            with tf.GradientTape() as tape:\n",
    "                embedding = model(image_batch)\n",
    "                unscaled_param = tf.constant(embedding * output_scaler.var_ ** 0.5 + output_scaler.mean_)\n",
    "                final = generate_guassian(unscaled_param, (48,48))\n",
    "                loss = custom_weighted_mse_loss(image_batch, final, n)\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            running_loss += loss.numpy()\n",
    "        average_loss = running_loss / len(dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss}\")\n",
    "\n",
    "if save_model:\n",
    "    model.save(\"Gaussian_Modle.keras\")\n",
    "\n",
    "if load_model:\n",
    "    pass\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Quantizing\n",
    "\n",
    "import qkeras\n",
    "from qkeras.estimate import print_qstats\n",
    "from qkeras.utils import model_quantize\n",
    "from qkeras.utils import quantized_model_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of operations in model:\n",
      "    conv2d                        : 290400 (smult_4_8)\n",
      "    conv2d_1                      : 117600 (smult_4_4)\n",
      "    dense                         : 14112 (smult_4_4)\n",
      "    dense_1                       : 5096  (smult_4_4)\n",
      "    dense_2                       : 260   (smult_4_4)\n",
      "\n",
      "Number of operation types in model:\n",
      "    smult_4_4                     : 137068\n",
      "    smult_4_8                     : 290400\n",
      "\n",
      "Weight profiling:\n",
      "    conv2d_weights                 : 150   (4-bit unit)\n",
      "    conv2d_bias                    : 6     (4-bit unit)\n",
      "    conv2d_1_weights               : 2400  (4-bit unit)\n",
      "    conv2d_1_bias                  : 16    (4-bit unit)\n",
      "    dense_weights                  : 14112 (4-bit unit)\n",
      "    dense_bias                     : 98    (4-bit unit)\n",
      "    dense_1_weights                : 5096  (4-bit unit)\n",
      "    dense_1_bias                   : 52    (4-bit unit)\n",
      "    dense_2_weights                : 260   (4-bit unit)\n",
      "    dense_2_bias                   : 5     (4-bit unit)\n",
      "\n",
      "Weight sparsity:\n",
      "... quantizing model\n",
      "    conv2d                         : 0.1090\n",
      "    conv2d_1                       : 0.0811\n",
      "    dense                          : 0.1064\n",
      "    dense_1                        : 0.0975\n",
      "    dense_2                        : 0.0830\n",
      "    ----------------------------------------\n",
      "    Total Sparsity                 : 0.1013\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Post Training Quantization\n",
    "save_qmodel = NO\n",
    "\n",
    "q_dict = {\n",
    "    \"QConv2D\": {\n",
    "        \"kernel_quantizer\": \"quantized_bits(4,0,1)\",\n",
    "        \"bias_quantizer\": \"quantized_bits(4,0,1)\"\n",
    "    },\n",
    "    \"QDense\": {\n",
    "        \"kernel_quantizer\": \"quantized_bits(4,0,1)\",\n",
    "        \"bias_quantizer\": \"quantized_bits(4,0,1)\"\n",
    "    },\n",
    "    \"QBatchNormalization\": {},\n",
    "\n",
    "    \"QActivation\": \"quantized_relu(4,0)\"\n",
    "}\n",
    "\n",
    "qmodel = model_quantize(model, q_dict, 4, transfer_weights=True)\n",
    "print_qstats(qmodel)\n",
    "\n",
    "if save_qmodel:\n",
    "    qmodel.save(\"Quantized_Gaussian_Modle.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: BENCHMARKS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qkeras-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
