{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables: \n",
    "\n",
    "YES = 1\n",
    "NO = 0\n",
    "\n",
    "DATA_DIR = '/home/pujan/Research/RHEED/Data/' # Change to your DATA PATH\n",
    "using_GPU = YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import h5py\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy.optimize import least_squares\n",
    "from dask import delayed, compute\n",
    "from dask.distributed import Client\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from qkeras import *\n",
    "\n",
    "%matplotlib inline\n",
    "output_scaler = StandardScaler()\n",
    "if(using_GPU):\n",
    "    print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read H5 Data File:\n",
    "\n",
    "RHEED_data_file = DATA_DIR + 'RHEED_4848_test6.h5'\n",
    "spot = 'spot_2'\n",
    "h5 = h5py.File(RHEED_data_file, 'r')\n",
    "\n",
    "raw_data = []\n",
    "for growth in h5.keys():\n",
    "    raw_data.extend(h5[growth][spot])\n",
    "raw_data = np.array(raw_data).astype(np.float32)\n",
    "raw_data = np.expand_dims(raw_data, axis=-1).astype(np.float32) # if (batch_size, height, width, channels)\n",
    "\n",
    "print(f'[Raw Images Shape]: {raw_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize w/ image max\n",
    "\n",
    "normalized_images = []\n",
    "normalized_factor = []\n",
    "for image in tqdm(raw_data):\n",
    "    normalized_images.append(image / np.max(image))\n",
    "    normalized_factor.append(np.max(image))\n",
    "normalized_images = np.array(normalized_images).astype(np.float32)\n",
    "normalized_factor = np.array(normalized_factor).astype(np.float32)\n",
    "\n",
    "print(f'[Normalized Images Shape]: {normalized_images.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Labels:\n",
    "load_labels = YES # (Takes <1 min to load, ~40 mins to generate)\n",
    "\n",
    "# Import From File\n",
    "\n",
    "if load_labels:\n",
    "    RHEED_LABEL_FILE = DATA_DIR + 'Estimated_Labels_PP.npy'\n",
    "    estimated_labels = np.load(RHEED_LABEL_FILE)\n",
    "\n",
    "# Generate :(\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(f'[Estimated Labels Shape]: {estimated_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataSet:\n",
    "batch_size = 1000\n",
    "dataset_arr = normalized_images\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dataset_arr)\n",
    "dataset = dataset.shuffle(dataset_arr.shape[0], reshuffle_each_iteration=True)\n",
    "dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Functions: (TENSORFLOW)\n",
    "print_example_guassian = NO\n",
    "print_example_loss = NO\n",
    "\n",
    "# mean_x, mean_y, cov_x, cov_y, theta\n",
    "def generate_guassian(batch, image_shape):\n",
    "    batch_size = batch.shape[0]\n",
    "    batch = tf.expand_dims(tf.expand_dims(batch, axis=-1), axis=-1)\n",
    "    x0, y0, sigma_x, sigma_y, theta = tf.cast(tf.unstack(batch, axis=-3), tf.float32)\n",
    "    \n",
    "    x_range = tf.range(start=0, limit=image_shape[0], delta=1)\n",
    "    y_range = tf.range(start=0, limit=image_shape[1], delta=1)\n",
    "    X_coord, Y_coord = tf.meshgrid(x_range, y_range, indexing='xy')\n",
    "    X_coord = tf.cast(tf.expand_dims(X_coord, axis=0), tf.float32)\n",
    "    Y_coord = tf.cast(tf.expand_dims(Y_coord, axis=0), tf.float32)\n",
    "    \n",
    "    X_coord = tf.tile(X_coord, [batch_size, 1, 1])\n",
    "    Y_coord = tf.tile(Y_coord, [batch_size, 1, 1])\n",
    "    \n",
    "    a = tf.math.pow(tf.math.cos(theta), 2) / (2 * tf.math.pow(sigma_x, 2)) + tf.math.pow(tf.math.sin(theta), 2) / (2 * tf.math.pow(sigma_y, 2))\n",
    "    b = -1 * tf.math.sin(theta) * tf.math.cos(theta) / (2 * tf.math.pow(sigma_x, 2)) + tf.math.sin(theta) * tf.math.cos(theta) / (2 * tf.math.pow(sigma_y, 2))\n",
    "    c = tf.math.pow(tf.math.sin(theta), 2) / (2 * tf.math.pow(sigma_x, 2)) + tf.math.pow(tf.math.cos(theta), 2) / (2 * tf.math.pow(sigma_y, 2))\n",
    "\n",
    "    img = tf.exp(-1 * (a * (X_coord - x0) ** 2 + 2 * b * (X_coord - x0) * (Y_coord - y0) + c * (Y_coord - y0) ** 2))\n",
    "\n",
    "    return tf.expand_dims(img, axis=-1) # if (batch_size, height, width, channels)\n",
    "    return tf.expand_dims(img, axis=1)  # if (batch_size, channels, height, width)\n",
    "\n",
    "def custom_weighted_mse_loss(I, J, n):\n",
    "  W = tf.pow(I, n)\n",
    "\n",
    "  squared_diffs = tf.pow(I - J, 2)\n",
    "\n",
    "  weighted_squared_diffs = W * squared_diffs\n",
    "\n",
    "  loss = tf.reduce_mean(weighted_squared_diffs)\n",
    "\n",
    "  return loss\n",
    "\n",
    "if print_example_guassian:\n",
    "    image_shape = (48, 48)\n",
    "    batch = tf.convert_to_tensor([\n",
    "        [21.8558168, 24.50041009, 10.31268177, 9.1700225, 0.72681534]\n",
    "        , [21.76068143, 24.37956637, 10.30043488, 9.15426013, 0.72655111]\n",
    "        , [21.72363929, 24.31050759, 10.33800891, 9.18570812, 0.72644599]\n",
    "        , [21.72777699, 24.29306623, 10.30178808, 9.14728058, 0.72610718]\n",
    "        , [21.79849472, 24.34649405, 10.32683150, 9.16259293, 0.72573213]\n",
    "    ])\n",
    "    generated_imgs = generate_guassian(batch, image_shape)\n",
    "    plt.imshow(tf.squeeze(generated_imgs[0]))\n",
    "    plt.show()\n",
    "\n",
    "if print_example_loss:\n",
    "    I = tf.random.normal((5, 1, 48, 48))\n",
    "    J = tf.random.normal((5, 1, 48, 48))\n",
    "    n = 2\n",
    "    loss = custom_weighted_mse_loss(I, J, n)\n",
    "    print(\"[Custom Weighted MSE Loss]:\", loss.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        # Quantized Conv2D Layer\n",
    "        QConv2DBatchnorm(\n",
    "            filters=6, kernel_size=5, strides=1, padding='valid',\n",
    "            kernel_quantizer=\"quantized_bits(8, 0, 1)\",  # 8-bit weights\n",
    "            bias_quantizer=\"quantized_bits(8, 0, 1)\",  # 8-bit biases\n",
    "        ),\n",
    "        # Quantized Activation\n",
    "        QActivation(\"quantized_relu(8, 0)\"),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=4, strides=4),\n",
    "\n",
    "        # Second Quantized Conv2D Layer\n",
    "        QConv2DBatchnorm(\n",
    "            filters=16, kernel_size=5, strides=1, padding='valid',\n",
    "            kernel_quantizer=\"quantized_bits(8, 0, 1)\",  # 8-bit weights\n",
    "            bias_quantizer=\"quantized_bits(8, 0, 1)\",  # 8-bit biases\n",
    "        ),\n",
    "        # Quantized Activation\n",
    "        QActivation(\"quantized_relu(8, 0)\"),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "        # Flatten for Dense Layers\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        # First Quantized Dense Layer\n",
    "        QDense(\n",
    "            units=98,\n",
    "            kernel_quantizer=\"quantized_bits(8, 0, 1)\",  # 8-bit weights\n",
    "            bias_quantizer=\"quantized_bits(8, 0, 1)\",  # 8-bit biases\n",
    "        ),\n",
    "        QActivation(\"quantized_relu(8, 0)\"),\n",
    "\n",
    "        # Second Quantized Dense Layer\n",
    "        QDense(\n",
    "            units=52,\n",
    "            kernel_quantizer=\"quantized_bits(8, 0, 1)\",  # 8-bit weights\n",
    "            bias_quantizer=\"quantized_bits(8, 0, 1)\",  # 8-bit biases\n",
    "        ),\n",
    "        QActivation(\"quantized_relu(8, 0)\"),\n",
    "\n",
    "        # Final Output Layer\n",
    "        QDense(\n",
    "            units=5,\n",
    "            kernel_quantizer=\"quantized_bits(8, 0, 1)\",  # 8-bit weights\n",
    "            bias_quantizer=\"quantized_bits(8, 0, 1)\",  # 8-bit biases\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the quantization-aware model\n",
    "model.compile(optimizer='adam', loss=custom_weighted_mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "train_model = YES\n",
    "save_model = YES\n",
    "load_model = NO\n",
    "\n",
    "if train_model:\n",
    "    best_loss = float('inf')\n",
    "    num_epochs = 200\n",
    "    lr = 0.0001\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    n = 1\n",
    "\n",
    "    scale = tf.constant([48, 48, 24, 24, np.pi/2])\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            n += 0.1\n",
    "\n",
    "        for image_batch in tqdm(dataset): \n",
    "            with tf.GradientTape() as tape:\n",
    "                embedding = model(image_batch)\n",
    "                unscaled_param = tf.constant(embedding * scale)\n",
    "                final = generate_guassian(unscaled_param, (48, 48))\n",
    "                loss = custom_weighted_mse_loss(image_batch, final, n)\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            running_loss += loss.numpy()\n",
    "        average_loss = running_loss / len(dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss}\")\n",
    "\n",
    "if save_model:\n",
    "    model.save(f'{DATA_DIR}/Models/[0,8]Gaussian.keras')\n",
    "\n",
    "if load_model:\n",
    "    model = tf.keras.models.load_model(\"Gaussian_Model.keras\")\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RHEED",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
